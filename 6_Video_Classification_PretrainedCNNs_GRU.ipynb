{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c4c41e1-a5fd-4b7a-843c-1343533491d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import util\n",
    "import model_builder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63190c4d-8b62-40fc-a9ba-a1b788788e33",
   "metadata": {},
   "source": [
    "Working plan - Since it's seen that MobileNetV2 + GRU gave an adequately good result, I want to try the architecture (the best alone or the top 5) on some variations:\n",
    "1. on the same videos decomposed into more number of frames (I did 16, try 32 and 64)\n",
    "2. on a different dataset (I used DFD, try CelebDF)\n",
    "3. using xceptionnet or some other pretrained model (so adjust image sizes accordingly)\n",
    "\n",
    "Make generic functions so that any data, any number of frames, and any pretrained model can be used. Save all the best ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04ed364b-f2a4-49cd-88ba-d775c2b327c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r'data'\n",
    "data_sources = ['DFD', 'CelebDF']\n",
    "num_frames = [16, 32, 64, 128, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "358e6350-4011-4bac-bbfb-a4822936a9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88766031-aaa8-41cd-a2fe-a3a4608a95ac",
   "metadata": {},
   "source": [
    "# DFD More Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af244e9a-0457-41d7-8f51-8e69d224082d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Model: MobileNetV2, Image Size: (224, 224)\n",
      "TRAIN set: 140 videos\n",
      "VAL set: 30 videos\n",
      "TEST set: 30 videos\n",
      "TRAIN set: 140 videos\n"
     ]
    }
   ],
   "source": [
    "labels1, classifier1, (classifier_loss1, classifier_acc1) = model_builder.train_test_classifier(\n",
    "    data_dir=os.path.join(base_dir, 'DFD'),\n",
    "    num_frames=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a408caf6-8db0-4096-b2b8-79e9f425c5fc",
   "metadata": {},
   "source": [
    "# DFD EfficientNetB3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1dbfe7-28ec-44f5-ae49-f53768f38ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2, classifier2, (classifier_loss2, classifier_acc2) = model_builder.train_test_classifier(\n",
    "    data_dir=os.path.join(base_dir, 'DFD'),\n",
    "    num_frames=16,\n",
    "    img_model_name='EfficientNetB3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e57d581-5bf6-414b-919a-1e49b7d3f450",
   "metadata": {},
   "source": [
    "# CelebDF (best pretrained model) & (best num frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775f5f65-bcb0-4cb3-a67a-1e3c609dafcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2, classifier2, (classifier_loss2, classifier_acc2) = model_builder.train_test_classifier(\n",
    "    data_dir=os.path.join(base_dir, 'CelebDF'),\n",
    "    num_frames=,\n",
    "    img_model_name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3890d1-7f7e-4ffb-a072-f3832f0dff61",
   "metadata": {},
   "source": [
    "* Adding more FC layers and more GRUs seems to improve the performance, but when the number of FCs exceed GRUs the performance drops.\n",
    "* Including dropouts between GRU and FC layer and between the FCs, also result in better performing models, while including BatchNormalization gives mixed results.\n",
    "* The best performing achitecture is one with 2 GRUs and 2 FCs with dropouts between GRU-FC and between FCs, with an accuracy of **66.7%** which is also the highest accuracy obtained among all the experimented models. The second highest accuracy seen is **63.3%** from the model having 3 GRUs with BatchNormalization between every pair and 2 FC layers with dropouts before and after each.\n",
    "\n",
    "**It should also be noted that these models were extremely quick to train, which made trying out several different architectures very easy.**\n",
    "\n",
    "* This architecture can be tuned further with the inclusion of different regularization parameters, different dropout rates, different optimizers, and momentum-based or scheduled learning rates.\n",
    "  * Since, the training is fast as it is, adding momentum may not necessarily help.\n",
    "  * Scheduling the learning rates and making it slower after a while may have higher scope of giving an improvement, even though all of the above trials used a small learning rate of 1e-5 (perhaps even smaller learning rates could help in this case).\n",
    "\n",
    "* Furthermore, we could also try other pretrained models for obtaining the embeddings. But we need to take care of the sizes of the images that are fed into those models.\n",
    "  * densenet, efficientnetb0, mobilenetv2, resnet50 -> 224x224\n",
    "  * xception, inceptionv3 -> 299x299\n",
    "  * efficientnetb3 -> 300x300\n",
    "\n",
    "**Regardless of the model and technique used, we don't appear to get any high values of accuracy. This is due to the small size of the dataset and also because of the nature of the dataset. The deepfake videos aren't entirely AI-generated, instead the faces/expressions alone, of the people in the videos, have been swapped/altered. So, our model needs to identify the fakeness of the video from a very small spatial range of the frames. That is a sensitive task, and a model will only be able to handle that if it were fed a significantly large dataset to learn from.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
