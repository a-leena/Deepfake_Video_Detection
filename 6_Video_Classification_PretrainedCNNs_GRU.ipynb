{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c4c41e1-a5fd-4b7a-843c-1343533491d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import util\n",
    "import model_builder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63190c4d-8b62-40fc-a9ba-a1b788788e33",
   "metadata": {},
   "source": [
    "Working plan - Since it's seen that MobileNetV2 + GRU gave an adequately good result, I want to try the architecture (the best alone or the top 5) on some variations:\n",
    "1. on the same videos decomposed into more number of frames (I did 16, try 32 and 64)\n",
    "2. on a different dataset (I used DFD, try CelebDF)\n",
    "3. using xceptionnet or some other pretrained model (so adjust image sizes accordingly)\n",
    "\n",
    "Make generic functions so that any data, any number of frames, and any pretrained model can be used. Save all the best ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04ed364b-f2a4-49cd-88ba-d775c2b327c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r'data'\n",
    "data_sources = ['DFD', 'CelebDF']\n",
    "num_frames = [16, 32, 64, 128, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "358e6350-4011-4bac-bbfb-a4822936a9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88766031-aaa8-41cd-a2fe-a3a4608a95ac",
   "metadata": {},
   "source": [
    "# DFD More Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af244e9a-0457-41d7-8f51-8e69d224082d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Model: MobileNetV2, Image Size: (224, 224)\n",
      "TRAIN set: 140 videos\n",
      "VAL set: 30 videos\n",
      "TEST set: 30 videos\n",
      "TRAIN set: 140 videos\n"
     ]
    }
   ],
   "source": [
    "labels1, classifier1, (classifier_loss1, classifier_acc1) = model_builder.train_test_classifier(\n",
    "    data_dir=os.path.join(base_dir, 'DFD'),\n",
    "    num_frames=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a408caf6-8db0-4096-b2b8-79e9f425c5fc",
   "metadata": {},
   "source": [
    "# DFD EfficientNetB3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1dbfe7-28ec-44f5-ae49-f53768f38ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2, classifier2, (classifier_loss2, classifier_acc2) = model_builder.train_test_classifier(\n",
    "    data_dir=os.path.join(base_dir, 'DFD'),\n",
    "    num_frames=16,\n",
    "    img_model_name='EfficientNetB3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e57d581-5bf6-414b-919a-1e49b7d3f450",
   "metadata": {},
   "source": [
    "# CelebDF (best pretrained model) & (best num frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775f5f65-bcb0-4cb3-a67a-1e3c609dafcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2, classifier2, (classifier_loss2, classifier_acc2) = model_builder.train_test_classifier(\n",
    "    data_dir=os.path.join(base_dir, 'CelebDF'),\n",
    "    num_frames=,\n",
    "    img_model_name='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
